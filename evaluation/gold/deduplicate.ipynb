{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import collections\n",
    "import json\n",
    "\n",
    "import krippendorff\n",
    "import numpy as np\n",
    "from pydantic import BaseModel\n",
    "from rapidfuzz import fuzz\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "from evaluation.utils import get_annotations, suggestions_are_same\n",
    "from evaluation.utils import get_experiment_infos"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class StopwatchSuggestion(BaseModel):\n",
    "    time: float  # the time the annotation happened\n",
    "    matches: list[str]  # the list of strings the suggestion must match to satisfy this label\n",
    "    antimatches: list[str] | None = None  # a list of strings that cannot match\n",
    "\n",
    "\n",
    "all_stopwatch_annotations = {}\n",
    "with open(\"gold-stopwatch.json\") as f:\n",
    "    stopwatch_annotation_data = json.load(f)\n",
    "    for experiment_id, stopwatch_annotations in stopwatch_annotation_data.items():\n",
    "        all_stopwatch_annotations[experiment_id] = [\n",
    "            StopwatchSuggestion.model_validate(a) for a in stopwatch_annotations\n",
    "        ]\n",
    "\n",
    "experiments = get_experiment_infos()"
   ],
   "id": "29eea42b51531ec1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## human annotator stuff",
   "id": "4b8ad67824c8ea33"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_annotation_index(experiment_id):\n",
    "    annotations = list(get_annotations(experiment_id))\n",
    "    annotations_by_suggestion_id = collections.defaultdict(list)\n",
    "\n",
    "    # go through the human annotations and build up an index\n",
    "    for annotation in annotations:\n",
    "        annotations_by_suggestion_id[annotation.suggestion_id].append(annotation)\n",
    "\n",
    "    # remove all suggestions that are only copies\n",
    "    for suggestion_id, suggestion_annotations in annotations_by_suggestion_id.copy().items():\n",
    "        if all(\"copied\" in a.why for a in suggestion_annotations):\n",
    "            annotations_by_suggestion_id.pop(suggestion_id)\n",
    "\n",
    "    return annotations_by_suggestion_id\n",
    "\n",
    "\n",
    "# annotations_by_suggestion_id"
   ],
   "id": "7d4aa62f6d66f65c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### IAA",
   "id": "c9c44501b64f164c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# calculate IAA with cohen kappa\n",
    "y1 = []\n",
    "y2 = []\n",
    "for experiment in experiments:\n",
    "    for suggestion_id, suggestion_annotations in get_annotation_index(experiment.id).items():\n",
    "        if len(suggestion_annotations) == 2:\n",
    "            y1.append(suggestion_annotations[0].score > 0)\n",
    "            y2.append(suggestion_annotations[1].score > 0)\n",
    "cohen_kappa_score(y1, y2)"
   ],
   "id": "f34a4e67ba0138d4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "sum(1 for x, y in zip(y1, y2) if x != y)",
   "id": "cb1f89522f374d8d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# krippendorf alpha\n",
    "annotators = [\"osowande\", \"akeri13\", \"jludan\", \"osgoodev\", \"feshbach\", \"pdotsamp\", \"andrz\"]\n",
    "seen_suggestion_ids = []\n",
    "annotation_count = sum(len(list(get_annotations(experiment.id))) for experiment in experiments)\n",
    "reliability_data = np.empty((len(annotators), annotation_count))\n",
    "reliability_data.fill(np.nan)\n",
    "\n",
    "for experiment in experiments:\n",
    "    for annotation in get_annotations(experiment.id):\n",
    "        if annotation.who not in annotators:\n",
    "            continue\n",
    "        if annotation.suggestion_id not in seen_suggestion_ids:\n",
    "            seen_suggestion_ids.append(annotation.suggestion_id)\n",
    "        row_idx = seen_suggestion_ids.index(annotation.suggestion_id)\n",
    "        reliability_data[annotators.index(annotation.who)][row_idx] = annotation.score"
   ],
   "id": "533279d503166088",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "krippendorff.alpha(reliability_data, value_domain=[-2.0, -1.0, 1.0, 2.0], level_of_measurement=\"ordinal\")",
   "id": "84ed22e370bdc1c7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Merge contiguous speech from the same NPC for partial ratio",
   "id": "b39fad09c043780a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from rapidfuzz.utils import default_process\n",
    "import itertools\n",
    "\n",
    "\n",
    "def myratio(s1, s2, **kwargs):\n",
    "    len_ratio = (len(s1) / len(s2)) if len(s1) > len(s2) else (len(s2) / len(s1))\n",
    "    len_ratio = ((len_ratio - 1) / 5) + 1\n",
    "    return fuzz.token_set_ratio(s1, s2, **kwargs) / len_ratio\n",
    "\n",
    "\n",
    "same_suggestion_ids = {}\n",
    "for experiment in experiments:\n",
    "    experiment_id = experiment.id\n",
    "    same_pairs = []\n",
    "    annotations_by_suggestion_id = get_annotation_index(experiment_id)\n",
    "    for (id1, an1), (id2, an2) in itertools.permutations(annotations_by_suggestion_id.items(), 2):\n",
    "        an1 = an1[0]\n",
    "        an2 = an2[0]\n",
    "        if not (\n",
    "            an1.entry.suggestion[\"suggest_type\"] == \"foundry\"\n",
    "            and an1.entry.suggestion[\"action\"][\"type\"] == \"send_npc_speech\"\n",
    "        ):\n",
    "            continue\n",
    "        if suggestions_are_same(\n",
    "            an1.entry,\n",
    "            an2.entry,\n",
    "            tolerance=300 if an1.score > 0 or an2.score > 0 else 30,\n",
    "            npc_speech_similarity_ratio=myratio,\n",
    "            npc_speech_similarity_threshold=80,\n",
    "        ):\n",
    "            # print(an1, an2)\n",
    "            print(an1.entry.suggestion[\"action\"][\"text\"], an1.score)\n",
    "            print(an2.entry.suggestion[\"action\"][\"text\"], an2.score)\n",
    "            print(\n",
    "                myratio(\n",
    "                    an1.entry.suggestion[\"action\"][\"text\"],\n",
    "                    an2.entry.suggestion[\"action\"][\"text\"],\n",
    "                    processor=default_process,\n",
    "                )\n",
    "            )\n",
    "            print()\n",
    "            same_pairs.append((an1.suggestion_id, an2.suggestion_id))\n",
    "\n",
    "    # build equivalence groups\n",
    "    equivalence_groups = []\n",
    "    for a, b in same_pairs:\n",
    "        for grp in equivalence_groups:\n",
    "            if a in grp or b in grp:\n",
    "                grp.add(a)\n",
    "                grp.add(b)\n",
    "                break\n",
    "        else:\n",
    "            equivalence_groups.append({a, b})\n",
    "    same_suggestion_ids[experiment_id] = equivalence_groups"
   ],
   "id": "605d84f985cafcaa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for session_id, sames in same_suggestion_ids.items():\n",
    "    print(session_id, len(sames))"
   ],
   "id": "c4dd4a66f716d6e9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Write for manual deduplication",
   "id": "c17724549ad68f5c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for experiment in experiments:\n",
    "    experiment_id = experiment.id\n",
    "\n",
    "    annotations_by_suggestion_id = get_annotation_index(experiment_id)\n",
    "\n",
    "    # if the score is all the same, only keep the first in a group\n",
    "    for suggestion_id, suggestion_annotations in annotations_by_suggestion_id.items():\n",
    "        if all(a.score > 0 for a in suggestion_annotations) or all(a.score < 0 for a in suggestion_annotations):\n",
    "            annotations_by_suggestion_id[suggestion_id] = [suggestion_annotations[0]]\n",
    "\n",
    "    # filter to only the positive annotations, make a copy\n",
    "    annotations_by_suggestion_id_all = annotations_by_suggestion_id.copy()\n",
    "    for suggestion_id, suggestion_annotations in annotations_by_suggestion_id.copy().items():\n",
    "        if not any(a.score > 0 for a in suggestion_annotations):\n",
    "            annotations_by_suggestion_id.pop(suggestion_id)\n",
    "\n",
    "    # add all the stopwatch annotations to any matching suggestion\n",
    "    stopwatch_annotations = all_stopwatch_annotations[experiment_id]\n",
    "    unmatched_stopwatch_annotations = []\n",
    "    for stopwatch_annotation in stopwatch_annotations:\n",
    "        # fix: make sure SG doesn't match SGK\n",
    "        if \"Ser Gordon\" in stopwatch_annotation.matches:\n",
    "            stopwatch_annotation.matches[stopwatch_annotation.matches.index(\"Ser Gordon\")] = 'Ser Gordon\"'\n",
    "\n",
    "        for suggestion_annotations in annotations_by_suggestion_id.values():\n",
    "            annotation = suggestion_annotations[0]\n",
    "            if all(s.lower() in str(annotation.entry.suggestion).lower() for s in stopwatch_annotation.matches) and (\n",
    "                stopwatch_annotation.time - 30\n",
    "            ) <= annotation.entry.end <= (stopwatch_annotation.time + 300):\n",
    "                suggestion_annotations.append(stopwatch_annotation)\n",
    "                break\n",
    "        else:\n",
    "            # not matched\n",
    "            # print(stopwatch_annotation)\n",
    "            unmatched_stopwatch_annotations.append(stopwatch_annotation)\n",
    "\n",
    "    # get the final dedup groups\n",
    "    dedup_groups = []  # (time, annotations[])\n",
    "    processed = set()\n",
    "    for suggestion_id, suggestion_annotations in annotations_by_suggestion_id.items():\n",
    "        if suggestion_id in processed:\n",
    "            continue\n",
    "\n",
    "        suggestion_annotations = suggestion_annotations.copy()\n",
    "\n",
    "        # merge equivalent annotations into the same dedup group\n",
    "        for equivalence_group in same_suggestion_ids[experiment_id]:\n",
    "            if suggestion_id in equivalence_group:\n",
    "                processed.add(suggestion_id)\n",
    "                for equiv_id in equivalence_group:\n",
    "                    if equiv_id == suggestion_id:\n",
    "                        continue\n",
    "                    processed.add(equiv_id)\n",
    "                    suggestion_annotations.extend(annotations_by_suggestion_id_all[equiv_id])\n",
    "\n",
    "        dedup_groups.append((suggestion_annotations[0].entry.end, suggestion_annotations))\n",
    "    for stopwatch_annotation in unmatched_stopwatch_annotations:\n",
    "        dedup_groups.append((stopwatch_annotation.time, [stopwatch_annotation]))\n",
    "\n",
    "    with open(f\"../annotations/to-dedup-{experiment_id}.jsonl\", \"w\") as f:\n",
    "        for ts, group in sorted(dedup_groups, key=lambda grp: grp[0]):\n",
    "            for item in group:\n",
    "                f.write(item.model_dump_json())\n",
    "                f.write(\"\\n\")\n",
    "            f.write(\"\\n\")"
   ],
   "id": "853fd3e4d5a6340b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "926d7c0406722657",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
